pip install tensorflow

!pip install keras

!pip install Keras-Preprocessing

from tensorflow.keras.utils import load_img,  img_to_array, array_to_img

import numpy as np
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense
from keras.models import Sequential
import glob, os, random

!pip install -q kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle

!kaggle datasets download -d asdasdasasdas/garbage-classification

#importing the google drive
from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/archive.zip

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from tensorflow.keras import layers
train_datagen = ImageDataGenerator(rescale = 1./255,zoom_range = 0.2,horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale = 1./255)

xtrain = train_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Garbage classification/Garbage classification',
                                           target_size =(64,64),
                                           class_mode = 'categorical',
                                           batch_size = 100)

xtest = test_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Garbage classification/Garbage classification',
                                           target_size =(64,64),
                                           class_mode = 'categorical',
                                           batch_size = 100)

base_path = '/content/drive/MyDrive/Dataset/Garbage classification/Garbage classification'
img_list = glob.glob(os.path.join(base_path, '*/*.jpg'))
print(len(img_list))

for i, img_path in enumerate(random.sample(img_list, 6)):
    img = load_img(img_path)
    img = img_to_array(img, dtype=np.uint8)

    plt.subplot(2, 3, i+1)
    plt.imshow(img.squeeze())

train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    vertical_flip=True,
    validation_split=0.1
)

train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    vertical_flip=True,
    validation_split=0.1
)

test_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.1
)

train_generator = train_datagen.flow_from_directory(
    base_path,
    target_size=(300, 300),
    batch_size=16,
    class_mode='categorical',
    subset='training',
    seed=0
)

validation_generator = test_datagen.flow_from_directory(
    base_path,
    target_size=(300, 300),
    batch_size=16,
    class_mode='categorical',
    subset='validation',
    seed=0
)

labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())

print(labels)

model = Sequential([
    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(300, 300, 3)),
    MaxPooling2D(pool_size=2),

    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),
    MaxPooling2D(pool_size=2),
    
    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),
    MaxPooling2D(pool_size=2),
    
    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),
    MaxPooling2D(pool_size=2),

    Flatten(),

    Dense(64, activation='relu'),

    Dense(6, activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])

model.summary()

model.fit_generator(train_generator, epochs=20, validation_data=validation_generator)

  test_x, test_y = validation_generator.__getitem__(1)

preds = model.predict(test_x)

plt.figure(figsize=(16, 16))
for i in range(16):
    plt.subplot(4, 4, i+1)
    plt.title('pred:%s / truth:%s' % (labels[np.argmax(preds[i])], labels[np.argmax(test_y[i])]))
    plt.imshow(test_x[i])


model.save('garbage.h5')







import numpy as np
import os
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from flask import Flask,render_template,request
app=Flask(__name__)

model=load_model(r"garbage.h5",compile=False)
@app.route('/')
def index():
    return render_template("index.html")
@app.route('/predict',methods=['GET','POST'])
def upload():
    if request.method=='POST':
        f=request.files['image']
        basepath=os.path.dirname(__file__)
        filepath=os.path.join(basepath,'uploads',f.filename)
        f.save(filepath)
        img=image.load_img(filepath,target_size=(64,64))
        x=image.img_to_array(img)
        x=np.expand_dims(x,axis=0)
        pred=np.argmax(model.predict(x),axis=1)
        index=['cardboad','glass','metal','paper', 'plastic', 'trash']
        text="The Classified Grabage is : " +str(index[pred[0]])
    return text

if __name__=='__main__':
    app.run()


pdf link:
https://drive.google.com/file/d/1Ws9D9NXanp1rb682Z6UwU_3ssIihJ7lo/view?usp=share_link
